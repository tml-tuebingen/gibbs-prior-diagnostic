{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
      "env: XLA_PYTHON_CLIENT_ALLOCATOR=platform\n"
     ]
    }
   ],
   "source": [
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import numpyro as npr\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import tqdm\n",
    "from math import *\n",
    "import numpyro.distributions as dist\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "matplotlib.rcParams['font.serif'] = 'Times'\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "plt = matplotlib.pyplot\n",
    "\n",
    "npr.set_platform('gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "sigma = 0.09\n",
    "nu = 12\n",
    "NUM_STEPS = 100\n",
    "\n",
    "\n",
    "def model(y, theta=None, rng_key=random.PRNGKey(1)):\n",
    "    \"\"\" PyMC3 example http://num.pyro.ai/en/0.6.0/examples/stochastic_volatility.html \"\"\"\n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "    num_steps = len(y) if y is not None else NUM_STEPS\n",
    "    \n",
    "    if theta is None:\n",
    "        log_vol = npr.sample(\n",
    "            'theta', dist.GaussianRandomWalk(scale=sigma, num_steps=num_steps), rng_key=rng_subkey\n",
    "        )\n",
    "    else:\n",
    "        log_vol = theta\n",
    "    \n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "    returns = npr.sample('y', dist.StudentT(df=nu, loc=0., scale=jnp.exp(log_vol)),\n",
    "                         rng_key=rng_subkey, obs=y)\n",
    "    \n",
    "    if theta is None and y is None:  \n",
    "        return log_vol  # Sample latent\n",
    "    else:  \n",
    "        return returns  # Given latent, sample y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "from numpyro.infer.autoguide import *\n",
    "\n",
    "\n",
    "def train_vb_diag(rng_key, y, pbar=True):    \n",
    "    guide = AutoDiagonalNormal(model)\n",
    "    lr = 1e-3\n",
    "    n_iter = 5000\n",
    "\n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=100))\n",
    "    svi_result = svi.run(rng_key, n_iter, y=y, progress_bar=pbar)\n",
    "    \n",
    "    return guide, svi_result.params\n",
    "\n",
    "\n",
    "def train_vb_full(rng_key, y, pbar=True):    \n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    lr = 5e-4  # Unstable with large lr\n",
    "    n_iter = 10000  # Compensate with larger num. of iterations\n",
    "    \n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=100))\n",
    "    svi_result = svi.run(rng_key, n_iter, y=y, progress_bar=pbar)\n",
    "    \n",
    "    return guide, svi_result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling $\\pi_G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTERIORS = ['vb_diag', 'vb_full', 'mcmc_long', 'mcmc_short']\n",
    "POSTERIOR_FUNCS = {\n",
    "    'vb_diag': train_vb_diag, \n",
    "    'vb_full': train_vb_full, \n",
    "}\n",
    "\n",
    "\n",
    "def sample_gibbs_prior(rng_key, posterior, T=100):\n",
    "    assert posterior in POSTERIORS\n",
    "    \n",
    "    theta_samples = []\n",
    "    \n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "    y_t  = model(y=None, rng_key=rng_subkey)\n",
    "    \n",
    "    pbar = tqdm.trange(T)\n",
    "    for t in pbar:     \n",
    "        rng_key, *subkeys = random.split(rng_key, 5)\n",
    "        \n",
    "        # Get q(theta | y_t)\n",
    "        if 'mcmc' not in posterior:\n",
    "            guide_t, params_t = POSTERIOR_FUNCS[posterior](subkeys[0], y=y_t, pbar=False)\n",
    "            theta_t = guide_t.sample_posterior(subkeys[1], params_t)['theta']\n",
    "        else:\n",
    "            num_warmup = 20 if 'long' in posterior else 5\n",
    "            num_samples = 20 if 'long' in posterior else 5\n",
    "            mcmc = MCMC(NUTS(model), num_warmup=num_warmup, num_samples=num_samples, progress_bar=False)\n",
    "            mcmc.run(subkeys[2], y_t)\n",
    "            theta_t = mcmc.get_samples()['theta'][-1]\n",
    "    \n",
    "        theta_samples.append(np.array(theta_t).copy())\n",
    "        \n",
    "        # Sample y_t\n",
    "        y_t  = model(y=None, theta=theta_t, rng_key=subkeys[3])\n",
    "        \n",
    "        pbar.set_description(f'[mean y_t: {y_t.mean():.3f}, mean theta_t: {np.mean(theta_t)}]')\n",
    "        \n",
    "    return theta_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mean y_t: 0.009, mean theta_t: -0.09571294486522675]: 100%|██████████| 100/100 [01:25<00:00,  1.17it/s]  \n",
      "[mean y_t: -0.012, mean theta_t: -0.29834285378456116]: 100%|██████████| 100/100 [04:58<00:00,  2.98s/it]\n",
      "[mean y_t: 0.030, mean theta_t: 0.24706442654132843]: 100%|██████████| 100/100 [02:04<00:00,  1.25s/it] \n",
      "[mean y_t: 0.018, mean theta_t: 0.12856708467006683]: 100%|██████████| 100/100 [01:17<00:00,  1.29it/s]   \n"
     ]
    }
   ],
   "source": [
    "for post in POSTERIORS:\n",
    "    thetas = sample_gibbs_prior(random.PRNGKey(9999), post, T=100)\n",
    "    np.save(f'../../results/volatility/{post}.npy', thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(42)\n",
    "rng_key, rng_subkey = random.split(rng_key)\n",
    "thetas_prior = dist.GaussianRandomWalk(scale=sigma, num_steps=NUM_STEPS).sample(rng_subkey, (10000,))\n",
    "np.save(f'../../results/volatility/prior_volatility.npy', thetas_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

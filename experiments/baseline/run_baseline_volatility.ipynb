{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import numpyro as npr\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import tqdm\n",
    "from math import *\n",
    "import numpyro.distributions as dist\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "matplotlib.rcParams['font.serif'] = 'Times'\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "plt = matplotlib.pyplot\n",
    "\n",
    "npr.set_platform('gpu')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
      "env: XLA_PYTHON_CLIENT_ALLOCATOR=platform\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/agustinus/miniconda3/lib/python3.9/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
      "  warnings.warn('jax.experimental.optimizers is deprecated, '\n",
      "/home/agustinus/miniconda3/lib/python3.9/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead\n",
      "  warnings.warn('jax.experimental.stax is deprecated, '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Hyperparams\n",
    "sigma = 0.09\n",
    "nu = 12\n",
    "NUM_STEPS = 100\n",
    "\n",
    "\n",
    "def model(y, theta=None, rng_key=random.PRNGKey(1)):\n",
    "    \"\"\" PyMC3 example http://num.pyro.ai/en/0.6.0/examples/stochastic_volatility.html \"\"\"\n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "    num_steps = len(y) if y is not None else NUM_STEPS\n",
    "    \n",
    "    if theta is None:\n",
    "        log_vol = npr.sample(\n",
    "            'theta', dist.GaussianRandomWalk(scale=sigma, num_steps=num_steps), rng_key=rng_subkey\n",
    "        )\n",
    "    else:\n",
    "        log_vol = theta\n",
    "    \n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "    returns = npr.sample('y', dist.StudentT(df=nu, loc=0., scale=jnp.exp(log_vol)),\n",
    "                         rng_key=rng_subkey, obs=y)\n",
    "    \n",
    "    if theta is None and y is None:  \n",
    "        return log_vol  # Sample latent\n",
    "    else:  \n",
    "        return returns  # Given latent, sample y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### VB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "from numpyro.infer.autoguide import *\n",
    "\n",
    "\n",
    "def train_vb_diag(rng_key, y, pbar=True):    \n",
    "    guide = AutoDiagonalNormal(model)\n",
    "    lr = 1e-3\n",
    "    n_iter = 5000\n",
    "\n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=100))\n",
    "    svi_result = svi.run(rng_key, n_iter, y=y, progress_bar=pbar)\n",
    "    \n",
    "    return guide, svi_result.params\n",
    "\n",
    "\n",
    "def train_vb_full(rng_key, y, pbar=True):    \n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    lr = 5e-4  # Unstable with large lr\n",
    "    n_iter = 10000  # Compensate with larger num. of iterations\n",
    "    \n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=100))\n",
    "    svi_result = svi.run(rng_key, n_iter, y=y, progress_bar=pbar)\n",
    "    \n",
    "    return guide, svi_result.params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "POSTERIORS = ['vb_diag', 'vb_full', 'mcmc_long', 'mcmc_short']\n",
    "POSTERIOR_FUNCS = {\n",
    "    'vb_diag': train_vb_diag, \n",
    "    'vb_full': train_vb_full, \n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline (Talts et al.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "M = 1e4\n",
    "R = 31 \n",
    "N = round(10.42*R)\n",
    "\n",
    "print(f'M = {M}, R = {R}, N = {N}, N*R = {N*R}')\n",
    "\n",
    "\n",
    "def run_baseline(posterior, rng_key=random.PRNGKey(1234)):    \n",
    "    results = np.zeros([N, R+1, NUM_STEPS])\n",
    "    \n",
    "    for n in tqdm.trange(N):\n",
    "        rng_key, *subkeys = random.split(rng_key, 6)\n",
    "        \n",
    "        theta_prior = dist.GaussianRandomWalk(scale=sigma, num_steps=NUM_STEPS).rsample(subkeys[0])\n",
    "        results[n, 0, :] = theta_prior  # (NUM_STEPS,)\n",
    "        \n",
    "        y  = model(y=None, theta=theta_prior, rng_key=subkeys[1])\n",
    "        \n",
    "        # Get q(theta | y_t)\n",
    "        if 'mcmc' not in posterior:\n",
    "            guide, params = POSTERIOR_FUNCS[posterior](subkeys[2], y=y, pbar=False)\n",
    "            theta = guide.sample_posterior(subkeys[3], params, (R,))['theta']\n",
    "        else:\n",
    "            num_warmup = 20 if 'long' in posterior else 5\n",
    "            num_samples = 20 if 'long' in posterior else 5\n",
    "            \n",
    "            mcmc = MCMC(\n",
    "                NUTS(model), \n",
    "                num_warmup=num_warmup, num_samples=num_samples, \n",
    "                progress_bar=False,\n",
    "                num_chains=R,\n",
    "                chain_method='vectorized'\n",
    "            )\n",
    "            mcmc.run(subkeys[4], y)\n",
    "            \n",
    "            # Last sample from each R chains\n",
    "            theta = np.array(\n",
    "                mcmc.get_samples(group_by_chain=True)['theta'][:, -1, :]\n",
    "            ).squeeze()\n",
    "            \n",
    "            assert theta.shape == (R, NUM_STEPS)\n",
    "            \n",
    "        results[n, 1:, :] = theta  # (R, NUM_STEPS)\n",
    "                \n",
    "    return results\n",
    "\n",
    "    \n",
    "for posterior in POSTERIORS:    \n",
    "    results = run_baseline(posterior=posterior)\n",
    "    np.save(f'../../results/baseline/baseline_{posterior}.npy', results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "M = 10000.0, R = 31, N = 323, N*R = 10013\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 323/323 [34:02<00:00,  6.32s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# %env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import numpyro as npr\n",
    "import tqdm as tqdm\n",
    "from math import *\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "\n",
    "npr.set_platform('gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(7.4827366, dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 10\n",
    "\n",
    "def model_true(y=None, theta=None, rng_key=random.PRNGKey(1)):\n",
    "    key, *subkeys = random.split(rng_key, 5)  # subkeys\n",
    "    \n",
    "    if theta is None:\n",
    "        # Sample from priors \\pi(\\mu, \\sigma^2)\n",
    "        mu = npr.sample('mu', dist.Normal(0, 1), rng_key=subkeys[0])\n",
    "        sigma_sq = npr.sample('sigma_sq', dist.Gamma(1, 1), rng_key=subkeys[1])\n",
    "    else:\n",
    "        mu, sigma_sq = theta\n",
    "    \n",
    "    # The true likelihood, sum of LogNormal rvs.\n",
    "    with npr.plate('L', L):\n",
    "        x = npr.sample('X', dist.LogNormal(mu, jnp.sqrt(sigma_sq)), rng_key=subkeys[2])\n",
    "        \n",
    "    out = npr.sample('Y', dist.Delta(x.sum(0)), rng_key=subkeys[3], obs=y)\n",
    "        \n",
    "    if theta is None and y is not None:\n",
    "        return (mu, sigma_sq)\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# Test\n",
    "model_true()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.8266345, dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_abc(y=None, theta=None, rng_key=random.PRNGKey(1)):\n",
    "    key, *subkeys = random.split(rng_key, 4)  # subkeys\n",
    "    \n",
    "    if theta is None:\n",
    "        # Sample from priors \\pi(\\mu, \\sigma^2)\n",
    "        mu = npr.sample('mu', dist.Normal(0, 1), rng_key=subkeys[0])\n",
    "        sigma_sq = npr.sample('sigma_sq', dist.Gamma(1, 1), rng_key=subkeys[1])\n",
    "    else:\n",
    "        mu, sigma_sq = theta\n",
    "    \n",
    "    # Approximate likelihood\n",
    "    beta_sq = jnp.log((jnp.exp(sigma_sq)-1)/L + 1)\n",
    "    alpha = mu + jnp.log(L) + 0.5*(sigma_sq - beta_sq)\n",
    "        \n",
    "    out = npr.sample('Y', dist.LogNormal(alpha, jnp.sqrt(beta_sq)), rng_key=subkeys[2], obs=y)\n",
    "    \n",
    "    if theta is None and y is not None:\n",
    "        return (mu, sigma_sq)\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# Test\n",
    "model_abc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer import SVI, Trace_ELBO, MCMC, NUTS\n",
    "from numpyro.infer.autoguide import *\n",
    "\n",
    "\n",
    "def laplace(rng_key, model, y, n_return_samples=1, pbar=False):    \n",
    "    key, *subkeys = random.split(rng_key, 4)\n",
    "    \n",
    "    guide = AutoLaplaceApproximation(model)\n",
    "    lr = 1e-3\n",
    "    n_iter = 5000\n",
    "\n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=1))\n",
    "    svi_result = svi.run(rng_key, n_iter, y=y, progress_bar=pbar)\n",
    "    \n",
    "    if n_return_samples == 1:\n",
    "        mu = guide.sample_posterior(subkeys[1], svi_result.params)['mu']\n",
    "        sigma_sq = guide.sample_posterior(subkeys[2], svi_result.params)['sigma_sq']\n",
    "\n",
    "        return mu, sigma_sq\n",
    "    else:\n",
    "        thetas = guide.sample_posterior(subkeys[1], svi_result.params, sample_shape=(n_return_samples,))\n",
    "        return np.array(thetas['mu']), np.array(thetas['sigma_sq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs-prior sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTERIORS = ['laplace']\n",
    "POSTERIOR_FUNCS = {\n",
    "    'laplace': laplace,\n",
    "}\n",
    "\n",
    "\n",
    "def sample_gibbs_prior(rng_key, posterior, T=100):\n",
    "    assert posterior in POSTERIORS\n",
    "    \n",
    "    theta_samples = []\n",
    "    \n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "    y_t  = model_true(y=None, theta=None, rng_key=rng_subkey)\n",
    "    \n",
    "    pbar = tqdm.trange(T)\n",
    "    for t in pbar:     \n",
    "        rng_key, *subkeys = random.split(rng_key, 3)\n",
    "        \n",
    "        # Get q(theta | y_t)\n",
    "        theta_t = POSTERIOR_FUNCS[posterior](subkeys[0], model_abc, y=y_t)\n",
    "        theta_samples.append(np.array(theta_t).copy())\n",
    "\n",
    "        # Sample y_t, always using the true model\n",
    "        y_t  = model_true(y=None, theta=theta_t, rng_key=subkeys[1])\n",
    "        \n",
    "        while y_t == inf:\n",
    "            rng_key, subkey = random.split(rng_key)\n",
    "            y_t  = model_true(y=None, theta=theta_t, rng_key=subkey)\n",
    "        \n",
    "        pbar.set_description(f'[y_t: {y_t:.3f}, theta_t: {np.array(theta_t)}]')\n",
    "        \n",
    "    return np.array(theta_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample $\\pi_G$ for the ABC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[y_t: 123.145, theta_t: [2.36252    0.11469223]]: 100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "rng_key = random.PRNGKey(1234)\n",
    "\n",
    "# Laplace\n",
    "thetas_laplace = sample_gibbs_prior(rng_key, 'laplace', T=100)\n",
    "np.save('../../results/log_normal/laplace.npy', thetas_laplace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sampling from the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample_prior(n_samples):\n",
    "    rng_keys = random.split(random.PRNGKey(1), 2)\n",
    "    mu = dist.Normal(0, 1).sample(rng_keys[0], (n_samples, 1))\n",
    "    sigma_sq = dist.Gamma(1, 1).sample(rng_keys[1], (n_samples, 1))\n",
    "    theta = np.concatenate((mu, sigma_sq), axis=-1)\n",
    "    return theta\n",
    "\n",
    "thetas_prior = sample_prior(n_samples=10000)\n",
    "np.save('../../results/log_normal/prior_log_normal.npy', thetas_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

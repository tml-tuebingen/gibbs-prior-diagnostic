{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import numpyro as npr\n",
    "import numpyro.distributions as dists\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import tqdm\n",
    "from math import *\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "matplotlib.rcParams['font.serif'] = 'Times'\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "plt = matplotlib.pyplot\n",
    "\n",
    "npr.set_platform('gpu')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
      "env: XLA_PYTHON_CLIENT_ALLOCATOR=platform\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/agustinus/miniconda3/lib/python3.9/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
      "  warnings.warn('jax.experimental.optimizers is deprecated, '\n",
      "/home/agustinus/miniconda3/lib/python3.9/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead\n",
      "  warnings.warn('jax.experimental.stax is deprecated, '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Hyperparams\n",
    "sigma = 0.09\n",
    "nu = 12\n",
    "NUM_STEPS = 100\n",
    "\n",
    "rng_key = jax.random.PRNGKey(9999)\n",
    "\n",
    "\n",
    "def model(y, theta=None, rng_key=random.PRNGKey(1)):\n",
    "    \"\"\" PyMC3 example http://num.pyro.ai/en/0.6.0/examples/stochastic_volatility.html \"\"\"\n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "    num_steps = len(y) if y is not None else NUM_STEPS\n",
    "    \n",
    "    if theta is None:\n",
    "        log_vol = npr.sample(\n",
    "            'theta', dists.GaussianRandomWalk(scale=sigma, num_steps=num_steps), rng_key=rng_subkey\n",
    "        )\n",
    "    else:\n",
    "        log_vol = theta\n",
    "    \n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "    returns = npr.sample('y', dists.StudentT(df=nu, loc=0., scale=jnp.exp(log_vol)),\n",
    "                         rng_key=rng_subkey, obs=y)\n",
    "    \n",
    "    if y is None:\n",
    "        return returns\n",
    "    else:  \n",
    "        return log_vol  # Given y, sample latent"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Approx. posteriors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "from numpyro.infer.autoguide import *\n",
    "\n",
    "\n",
    "def train_vb_diag(rng_key, y, pbar=True):    \n",
    "    guide = AutoDiagonalNormal(model)\n",
    "    lr = 1e-3\n",
    "    n_iter = 5000\n",
    "\n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=100))\n",
    "    svi_result = svi.run(rng_key, n_iter, y=y, progress_bar=pbar)\n",
    "        \n",
    "    return guide, svi_result.params\n",
    "\n",
    "\n",
    "def train_vb_full(rng_key, y, pbar=True):    \n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    lr = 5e-4  # Unstable with large lr\n",
    "    n_iter = 10000  # Compensate with larger num. of iterations\n",
    "    \n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=100))\n",
    "    svi_result = svi.run(rng_key, n_iter, y=y, progress_bar=pbar)\n",
    "        \n",
    "    return guide, svi_result.params\n",
    "\n",
    "\n",
    "def train_laplace(rng_key, y, pbar=True):    \n",
    "    guide = AutoLaplaceApproximation(model)\n",
    "    lr = 1e-3\n",
    "    n_iter = 5000\n",
    "\n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=1))\n",
    "    svi_result = svi.run(rng_key, n_iter, y=y, progress_bar=pbar)\n",
    "        \n",
    "    return guide, svi_result.params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sampling $\\pi_G$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "\n",
    "POSTERIORS = ['vb_diag', 'vb_full', 'mcmc_long', 'mcmc_short']\n",
    "POSTERIOR_FUNCS = {\n",
    "    'vb_diag': train_vb_diag, \n",
    "    'vb_full': train_vb_full, \n",
    "    # 'laplace': train_laplace,\n",
    "}\n",
    "\n",
    "\n",
    "def sample_gibbs_prior(rng_key, posterior, n_chains=5, T=1000):\n",
    "    r_hats, autocorrs = [], []\n",
    "\n",
    "    theta_samples = [[] for i in range(n_chains)]\n",
    "    y_ts = []\n",
    "    \n",
    "    for i in range(n_chains):\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        y_t_i = model(y=None, rng_key=subkey)\n",
    "        y_ts.append(100*y_t_i)  # Overdispersed initialization\n",
    "    \n",
    "    for t in tqdm.trange(T): \n",
    "        for i in range(n_chains):\n",
    "            rng_key, *subkeys = random.split(rng_key, 5)\n",
    "\n",
    "            # Get q(theta | y_t)\n",
    "            if 'mcmc' not in posterior:\n",
    "                guide_t_i, params_t_i = POSTERIOR_FUNCS[posterior](subkeys[0], y=y_ts[i], pbar=False)\n",
    "                theta_t_i = guide_t_i.sample_posterior(subkeys[1], params_t_i)['theta']\n",
    "            else:\n",
    "                num_warmup = 20 if 'long' in posterior else 5\n",
    "                num_samples = 20 if 'long' in posterior else 5\n",
    "                mcmc = MCMC(NUTS(model), num_warmup=num_warmup, num_samples=num_samples, progress_bar=False)\n",
    "                mcmc.run(subkeys[2], y_ts[i])\n",
    "                theta_t_i = mcmc.get_samples()['theta'][-1]\n",
    "                \n",
    "            theta_samples[i].append(np.array(theta_t_i).copy())\n",
    "\n",
    "            # Sample y_t\n",
    "            y_ts[i]  = model(y=None, theta=theta_t_i, rng_key=subkeys[3])  \n",
    "        \n",
    "    # Shape: (n_chains, n_samples, n_dim)\n",
    "    return np.array(theta_samples)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gather samples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for posterior in POSTERIORS:\n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "    theta_samples = sample_gibbs_prior(rng_subkey, posterior, n_chains=5, T=500)\n",
    "    theta_samples = np.array(theta_samples)\n",
    "\n",
    "    np.save(f'../../results/convergence/multi_chains_{posterior}.npy', theta_samples)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
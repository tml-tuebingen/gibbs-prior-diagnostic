{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
      "env: XLA_PYTHON_CLIENT_ALLOCATOR=platform\n"
     ]
    }
   ],
   "source": [
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda/\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import numpyro as npr\n",
    "import numpyro.distributions as dists\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import tqdm\n",
    "from math import *\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "matplotlib.rcParams['font.serif'] = 'Times'\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "plt = matplotlib.pyplot\n",
    "\n",
    "npr.set_platform('gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "sigma = 0.09\n",
    "nu = 12\n",
    "NUM_STEPS = 100\n",
    "\n",
    "\n",
    "def model(y, theta=None, rng_key=random.PRNGKey(1)):\n",
    "    \"\"\" PyMC3 example http://num.pyro.ai/en/0.6.0/examples/stochastic_volatility.html \"\"\"\n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "    num_steps = len(y) if y is not None else NUM_STEPS\n",
    "    \n",
    "    if theta is None:\n",
    "        log_vol = npr.sample(\n",
    "            'theta', dists.GaussianRandomWalk(scale=sigma, num_steps=num_steps), rng_key=rng_subkey\n",
    "        )\n",
    "    else:\n",
    "        log_vol = theta\n",
    "    \n",
    "    rng_key, rng_subkey = random.split(rng_key)\n",
    "    returns = npr.sample('y', dists.StudentT(df=nu, loc=0., scale=jnp.exp(log_vol)),\n",
    "                         rng_key=rng_subkey, obs=y)\n",
    "    \n",
    "    if theta is None and y is None:  \n",
    "        return log_vol  # Sample latent\n",
    "    else:  \n",
    "        return returns  # Given latent, sample y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approx. posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer import MCMC, NUTS, SVI, Trace_ELBO\n",
    "from numpyro.infer.autoguide import *\n",
    "from jax import jit\n",
    "\n",
    "\n",
    "@jit\n",
    "def vb_diag(rng_key, y):    \n",
    "    key, *subkeys = random.split(rng_key, 3)\n",
    "    \n",
    "    guide = AutoDiagonalNormal(model)\n",
    "    lr = 1e-3\n",
    "    n_iter = 5000\n",
    "\n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=100))\n",
    "    svi_result = svi.run(subkeys[0], n_iter, y=y, progress_bar=False)\n",
    "    \n",
    "    theta = guide.sample_posterior(subkeys[1], svi_result.params)['theta']\n",
    "    return theta\n",
    "\n",
    "@jit\n",
    "def vb_full(rng_key, y):    \n",
    "    key, *subkeys = random.split(rng_key, 3)\n",
    "    \n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    lr = 5e-4  # Unstable with large lr\n",
    "    n_iter = 10000  # Compensate with larger num. of iterations\n",
    "    \n",
    "    optimizer = npr.optim.ClippedAdam(step_size=lr)\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO(num_particles=100))\n",
    "    svi_result = svi.run(subkeys[0], n_iter, y=y, progress_bar=False)\n",
    "    \n",
    "    theta = guide.sample_posterior(subkeys[1], svi_result.params)['theta']\n",
    "    return theta\n",
    "\n",
    "@jit\n",
    "def mcmc_short(rng_key, y):    \n",
    "    mcmc = MCMC(NUTS(model), num_warmup=5, num_samples=5, progress_bar=False)\n",
    "    mcmc.run(rng_key, y)\n",
    "\n",
    "    theta = mcmc.get_samples()['theta'][-1]\n",
    "    return theta\n",
    "\n",
    "\n",
    "@jit\n",
    "def mcmc_long(rng_key, y):    \n",
    "    mcmc = MCMC(NUTS(model), num_warmup=20, num_samples=20, progress_bar=False)\n",
    "    mcmc.run(rng_key, y)\n",
    "\n",
    "    theta = mcmc.get_samples()['theta'][-1]\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling $\\pi_G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTERIORS = ['vb_diag', 'vb_full', 'mcmc_long', 'mcmc_short']\n",
    "POSTERIOR_FUNCS = {\n",
    "    'vb_diag': vb_diag, \n",
    "    'vb_full': vb_full, \n",
    "    'mcmc_short': mcmc_short,\n",
    "    'mcmc_long': mcmc_long\n",
    "}\n",
    "\n",
    "\n",
    "def sample_gibbs_prior(rng_key, posterior, n_chains=5, T=1000):\n",
    "    theta_samples = [[] for i in range(n_chains)]\n",
    "    y_ts = []\n",
    "    \n",
    "    for i in range(n_chains):\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        y_t_i = model(y=None, rng_key=subkey)\n",
    "        y_ts.append(100*y_t_i)  # Overdispersed initialization\n",
    "    \n",
    "    for t in tqdm.trange(T): \n",
    "        for i in range(n_chains):\n",
    "            rng_key, *subkeys = random.split(rng_key, 3)\n",
    "\n",
    "            # Get q(theta | y_t)\n",
    "            theta_t_i = POSTERIOR_FUNCS[posterior](subkeys[0], y=y_t_i)   \n",
    "            theta_samples[i].append(np.array(theta_t_i).copy())\n",
    "\n",
    "            # Sample y_t\n",
    "            y_ts[i]  = model(y=None, theta=theta_t_i, rng_key=subkeys[1])  \n",
    "        \n",
    "    # Shape: (n_chains, n_samples, n_dim)\n",
    "    return np.array(theta_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [14:35<00:00,  1.75s/it]\n",
      "100%|██████████| 500/500 [1:27:27<00:00, 10.49s/it]\n",
      "100%|██████████| 500/500 [11:53<00:00,  1.43s/it]\n",
      "100%|██████████| 500/500 [00:55<00:00,  9.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for posterior in POSTERIORS:\n",
    "    theta_samples = sample_gibbs_prior(random.PRNGKey(9999), posterior, n_chains=5, T=500)\n",
    "    theta_samples = np.array(theta_samples)\n",
    "\n",
    "    np.save(f'../../results/convergence/multi_chains_{posterior}.npy', theta_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
